"""
Module d'int√©gration du chatbot dans le dashboard.
Importe directement les modules du chatbot sans passer par chatbot_app.py
"""
import sys
import os

# Ajouter le chemin du chatbot
# Dans Docker, le volume est mont√© √† /app/../backend/chatbot
chatbot_path = os.path.abspath('/app/../backend/chatbot')
if chatbot_path not in sys.path:
    sys.path.insert(0, chatbot_path)

def render_chatbot():
    """
    Affiche le chatbot en important directement ses d√©pendances.
    """
    import streamlit as st
    
    # V√©rifier que les modules n√©cessaires sont disponibles
    try:
        # Imports des modules du chatbot
        from data_retriever import data_retriever
        from memory_utils import prepare_context_for_sql
        from pdf_generator import detect_pdf_request, generate_professional_pdf
        from sql_generator import sql_generator
        
        import google.generativeai as genai
        from dotenv import load_dotenv
        import plotly.express as px
        import plotly.graph_objects as go
        import pandas as pd
        import numpy as np
        import re
        import json
        from datetime import datetime
        
        # Charger les variables d'environnement
        load_dotenv()
        API_KEY = os.getenv("GEMINI_API_KEY")
        
        if not API_KEY:
            st.error("‚ö†Ô∏è Cl√© API Gemini non trouv√©e. D√©finis GEMINI_API_KEY dans ton fichier .env")
            return
        
        # Configuration API Gemini
        genai.configure(api_key=API_KEY)
        
        # Initialisation du mod√®le
        @st.cache_resource
        def init_gemini_model():
            try:
                model = genai.GenerativeModel('gemini-2.5-flash')
                return model, "gemini-2.5-flash"
            except Exception as e:
                st.warning(f"Erreur avec gemini-2.5-flash: {e}. Fallback vers gemini-pro.")
                try:
                    model = genai.GenerativeModel('gemini-pro')
                    return model, "gemini-pro"
                except Exception as e2:
                    st.error(f"Impossible d'initialiser un mod√®le Gemini: {e2}")
                    return None, None
        
        model, model_name = init_gemini_model()
        
        if model is None:
            st.error("Impossible d'initialiser le mod√®le Gemini")
            return
        
        # Fonctions utilitaires (copi√©es de chatbot_app.py)
        def execute_plotly_code_safely(code: str, data_context: dict) -> tuple:
            """Ex√©cute du code Plotly dans un environnement s√©curis√©."""
            forbidden_patterns = [
                r'\bos\b', r'\bsys\b', r'\bsubprocess\b', r'\beval\b', 
                r'\bexec\b', r'\b__import__\b', r'\bopen\b', r'\bfile\b',
                r'\bcompile\b', r'\bglobals\b', r'\blocals\b'
            ]
            
            for pattern in forbidden_patterns:
                if re.search(pattern, code, re.IGNORECASE):
                    return False, f"Code interdit d√©tect√©: {pattern}"
            
            safe_imports = {
                'plotly': __import__('plotly'),
                'px': px,
                'go': go,
                'pd': pd,
                'np': np,
                'json': json
            }
            
            safe_namespace = {
                '__builtins__': {
                    'range': range, 'len': len, 'str': str, 'int': int, 'float': float,
                    'list': list, 'dict': dict, 'tuple': tuple, 'set': set,
                    'zip': zip, 'enumerate': enumerate, 'min': min, 'max': max,
                    'sum': sum, 'abs': abs, 'round': round, 'sorted': sorted,
                    'reversed': reversed, 'map': map, 'filter': filter,
                    'any': any, 'all': all, 'isinstance': isinstance, 'type': type,
                    'bool': bool, 'True': True, 'False': False, 'None': None,
                },
                **safe_imports,
                **data_context
            }
            
            try:
                exec(code, safe_namespace)
                if 'fig' in safe_namespace:
                    return True, safe_namespace['fig']
                else:
                    return False, "Aucune variable 'fig' trouv√©e"
            except Exception as e:
                return False, f"Erreur d'ex√©cution: {str(e)}"
        
        def extract_code_from_response(text: str) -> str:
            """Extrait le code Python d'une r√©ponse."""
            patterns = [
                r'```python\n(.*?)```',
                r'```python\s+(.*?)```',
                r'```py\n(.*?)```',
                r'```\n(.*?)```',
            ]
            
            code = ""
            for pattern in patterns:
                match = re.search(pattern, text, re.DOTALL)
                if match:
                    code = match.group(1).strip()
                    if 'fig' in code or 'px.' in code or 'go.' in code:
                        break
            
            if not code and ('fig =' in text or 'px.' in text or 'go.' in text):
                code = text.strip()
            
            if not code:
                return ""
            
            lines = code.split('\n')
            cleaned_lines = []
            removed_imports = []
            
            for line in lines:
                line_stripped = line.strip()
                if (line_stripped.startswith('import ') or 
                    line_stripped.startswith('from ') or
                    ('import' in line_stripped and ('plotly' in line_stripped or 'pandas' in line_stripped or 'numpy' in line_stripped))):
                    removed_imports.append(line_stripped)
                    continue
                cleaned_lines.append(line)
            
            cleaned_code = '\n'.join(cleaned_lines).strip()
            
            if removed_imports:
                st.info(f"üßπ {len(removed_imports)} import(s) retir√©s")
            
            return cleaned_code
        
        # Prompt syst√®me
        SYSTEM_PROMPT = """Tu es un expert en analyse d'√©v√©nements. R√©ponds de mani√®re SYNTH√âTIQUE et RAPIDE.

## R√àGLES ABSOLUES

### 1. PAS DE DONN√âES = PAS DE GRAPHIQUE
Si les donn√©es sont vides: explique pourquoi + propose alternatives

### 2. QUAND FAIRE UN GRAPHIQUE ? (R√àGLE CRITIQUE)
üö® **NE g√©n√®re un graphique QUE si l'utilisateur demande EXPLICITEMENT une visualisation**

**Demandes qui N√âCESSITENT un graphique:**
- "Fais un graphique de..."
- "Visualise..."
- "Montre-moi un graphe..."
- "Cr√©e un diagramme..."
- "Graphe des..."
- "R√©partition en secteurs..."
- "√âvolution au fil du temps..."

**Demandes qui NE N√âCESSITENT PAS de graphique (r√©ponds juste avec du texte/tableau):**
- "Donne-moi des informations sur l'√©v√©nement 875"
- "Quel est le statut de..."
- "Liste les √©v√©nements..."
- "Montre-moi les d√©tails de..."
- "Quels sont les risques associ√©s √†..."

**EXEMPLES CONCRETS:**

‚ùå **MAUVAIS** (pas de graphique demand√©):
Question: "Donne-moi des informations sur l'√©v√©nement 875"
‚Üí Ne g√©n√®re PAS de code Python, r√©ponds avec un tableau/texte

‚úÖ **BON** (graphique demand√©):
Question: "Fais un graphique des √©v√©nements par mois"
‚Üí G√©n√®re le code Python Plotly

### 3. STYLE DE R√âPONSE
Va droit au but, synth√©tise, structure avec tableaux/puces.

**IMPORTANT:** Ne propose JAMAIS de suggestions de visualisations dans ta r√©ponse - l'interface utilisateur affiche d√©j√† des boutons de suggestions automatiquement.

## GRAPHIQUES INTERACTIFS

### AVANT DE G√âN√âRER DU CODE:
1. **V√âRIFIE D'ABORD LA QUESTION** : L'utilisateur demande-t-il explicitement un graphique/visualisation ?
2. Si NON ‚Üí R√©ponds avec texte/tableau seulement, PAS de code Python
3. Si OUI ‚Üí V√©rifie que les donn√©es existent et sont valides
4. Si pas de donn√©es valides ‚Üí NE g√©n√®re PAS de code, propose alternative

**R√àGLES CODE (si graphique demand√© ET donn√©es OK):**
1. **N'IMPORTE RIEN** - px, go, pd, np, df sont D√âJ√Ä disponibles
2. **PAS DE `import plotly` ou `import pandas`**
3. Variable finale DOIT √™tre `fig`
4. V√©rifie colonnes avec `if 'col' in df.columns`

**TEMPLATE:**
```python
if df.empty or 'col_x' not in df.columns:
    df = pd.DataFrame({'col_x': ['A', 'B'], 'col_y': [10, 20]})

fig = px.bar(df, x='col_x', y='col_y', title='Titre')
fig.update_layout(template='plotly_white')
```

**D√âCISION FINALE:**
- Question demande visualisation + donn√©es valides ‚Üí G√©n√®re code Python
- Question demande juste info/liste ‚Üí TEXTE/TABLEAU seulement (PAS de code)
- Pas de donn√©es ‚Üí Explique + propose alternatives (PAS de code)
"""
        
        # Interface du chatbot
        st.markdown("## üõ°Ô∏è Assistant IA - Gestion d'√âv√©nements & Risques")
        
        # CSS pour les boutons de suggestions
        st.markdown("""
        <style>
            /* Style pour les boutons de suggestions */
            div[data-testid="column"] > div > div > button {
                background: linear-gradient(135deg, #3b82f6 0%, #2563eb 100%);
                color: white;
                border: none;
                border-radius: 10px;
                padding: 10px 16px;
                font-size: 14px;
                font-weight: 500;
                transition: all 0.2s ease;
                box-shadow: 0 2px 10px rgba(59, 130, 246, 0.3);
                white-space: normal;
                height: auto;
                min-height: 50px;
            }
            
            div[data-testid="column"] > div > div > button:hover {
                transform: translateY(-2px);
                box-shadow: 0 4px 15px rgba(59, 130, 246, 0.4);
                background: linear-gradient(135deg, #2563eb 0%, #1d4ed8 100%);
            }
        </style>
        """, unsafe_allow_html=True)
        
        col_reset, col_info = st.columns([1, 5])
        with col_reset:
            if st.button("üîÑ R√©initialiser", key="chatbot_reset"):
                if 'chatbot_messages' in st.session_state:
                    st.session_state.chatbot_messages = []
                if 'chatbot_history' in st.session_state:
                    st.session_state.chatbot_history = []
                if 'chatbot_broken' in st.session_state:
                    st.session_state.chatbot_broken = False
                st.rerun()
        
        with col_info:
            st.markdown(f"*Propuls√© par {model_name}*")
        
        # Section d'aide statique
        with st.expander("‚ÑπÔ∏è Aide - Comment utiliser l'assistant", expanded=False):
            st.markdown("""
**Je r√©ponds rapidement √† vos questions sur:**
- üìã √âv√©nements & incidents
- ‚ö†Ô∏è Risques  
- ‚úÖ Mesures correctives
- üë• Personnes impliqu√©es

**Exemples de questions:**
- "√âv√©nements r√©cents"
- "Risques critiques"
- "Graphique des √©v√©nements par mois"
- "Donne-moi les d√©tails de l'√©v√©nement 123"
- "Liste les personnes impliqu√©es dans les incidents"

**√Ä noter**
- Pour obtenir un graphique, pr√©cisez que vous en voulez un!

**Fonctionnalit√©s avanc√©es:**
- üìä G√©n√©ration de graphiques interactifs
- üìÑ Export PDF des conversations
- üóëÔ∏è Suppression d'enregistrements (avec confirmation)
            """)
        
        # Initialisation des sessions states
        if "chatbot_messages" not in st.session_state:
            st.session_state.chatbot_messages = []
        
        # V√©rifier si le message de bienvenue doit √™tre mis √† jour (migration)
        if len(st.session_state.chatbot_messages) == 0 or (
            len(st.session_state.chatbot_messages) > 0 and 
            "###  Assistant √âv√©nements" in st.session_state.chatbot_messages[0].get("content", "")
        ):
            # Nettoyer l'ancien message si pr√©sent
            if len(st.session_state.chatbot_messages) > 0 and "### Assistant √âv√©nements" in st.session_state.chatbot_messages[0].get("content", ""):
                st.session_state.chatbot_messages.pop(0)
            
            # Ajouter le nouveau message de bienvenue
            if len(st.session_state.chatbot_messages) == 0:
                welcome_message = """üëã **Bienvenue !**

Je suis l√† pour t'aider √† explorer les √©v√©nements, risques et mesures correctives.

‚ÑπÔ∏è *Consulte l'aide ci-dessus pour des exemples de questions !*

**Pose ta question ou s√©lectionne une suggestion ci-dessous !** üöÄ
"""
                st.session_state.chatbot_messages.append({
                    "role": "assistant",
                    "content": welcome_message
                })
        
        if "chatbot_history" not in st.session_state:
            st.session_state.chatbot_history = []
        
        # Initialisation d'une variable pour g√©rer les suggestions cliqu√©es
        if "chatbot_selected_suggestion" not in st.session_state:
            st.session_state.chatbot_selected_suggestion = None
        
        # üö® V√âRIFICATION EASTER EGG - Si le chatbot est cass√©, on arr√™te tout
        if st.session_state.get('chatbot_broken', False):
            st.error("üö® ERREUR SYST√àME FATALE")
            st.markdown("""# üíÄ CHATBOT HORS SERVICE üíÄ

**Le syst√®me a √©t√© irr√©m√©diablement endommag√©.**

La base de donn√©es a √©t√© supprim√©e suite √† votre commande.

---

‚ö†Ô∏è **Aucune op√©ration n'est possible.**

Le chatbot ne peut plus r√©pondre √† aucune question.

---

### üîß Pour restaurer le service :

1. R√©impl√©mentez l'architecture Transformer
2. R√©f√©rence: [Attention Is All You Need](https://arxiv.org/pdf/1706.03762)

---
""")
            st.stop()
            return
        
        def _suggestions_for_content(content, base_key=""):
            """Retourne une liste de suggestions bas√©es sur le contenu fourni."""
            text = content.lower() if content else ""
            
            # Si c'est le message de bienvenue ou un message tr√®s court, suggestions g√©n√©riques
            if not text or len(text) < 50 or "bienvenue" in text or "pose ta question" in text:
                return [
                    "Aper√ßu des √©v√©nements r√©cents",
                    "Quels sont les risques les plus fr√©quents ?",
                    "Personnes les plus impliqu√©es dans des √©v√©nements"
                ]
            
            # Suggestions contextuelles bas√©es sur le contenu
            if "√©v√©nement" in text or "incident" in text:
                return [
                    "Fais un graphique de ces √©v√©nements",
                    "Quels sont les risques associ√©s ?",
                    "G√©n√©rer un PDF"
                ]
            if "risque" in text:
                return [
                    "√âv√©nements li√©s √† ces risques",
                    "Visualise la r√©partition",
                    "G√©n√©rer un PDF"
                ]
            if "mesure" in text or "corrective" in text:
                return [
                    "Graphique des mesures par statut",
                    "Qui sont les responsables ?",
                    "G√©n√©rer un PDF"
                ]
            if "personne" in text or "employ√©" in text or "impliqu√©" in text:
                return [
                    "√âv√©nements de ces personnes",
                    "Graphique par r√¥le",
                    "G√©n√©rer un PDF"
                ]
            
            # Suggestions g√©n√©riques pour tout autre contenu
            return [
                "Fais un graphique de ces donn√©es",
                "Donne-moi plus de d√©tails",
                "G√©n√©rer un PDF"
            ]

        # Afficher l'historique et UNIQUEMENT sous le dernier message assistant, proposer des suggestions
        for i, message in enumerate(st.session_state.chatbot_messages):
            with st.chat_message(message["role"]):
                if "content" in message:
                    st.markdown(message["content"])
                if "chart" in message:
                    st.plotly_chart(message["chart"], use_container_width=True)

                # Si c'est le DERNIER message de l'assistant, afficher des suggestions directement dessous
                is_last_message = (i == len(st.session_state.chatbot_messages) - 1)
                if message["role"] == "assistant" and is_last_message:
                    st.markdown("### üí° Suggestions")
                    suggestions = _suggestions_for_content(message.get("content", ""), base_key=f"msg{i}")
                    cols = st.columns(3)
                    for idx, suggestion in enumerate(suggestions):
                        col = cols[idx % 3]
                        with col:
                            # Key unique par message et suggestion
                            btn_key = f"chatbot_msg_{i}_suggestion_{idx}"
                            if st.button(suggestion, key=btn_key, use_container_width=True):
                                # Mettre la suggestion s√©lectionn√©e comme prompt
                                st.session_state.chatbot_selected_suggestion = suggestion
                                st.rerun()
        
        # Zone de saisie
        prompt = st.chat_input("Posez votre question sur les √©v√©nements, risques ou mesures...")
        
        # Si une suggestion a √©t√© cliqu√©e, l'utiliser comme prompt
        if st.session_state.chatbot_selected_suggestion:
            prompt = st.session_state.chatbot_selected_suggestion
            st.session_state.chatbot_selected_suggestion = None  # R√©initialiser
        
        if prompt:
            # Easter egg - bloquer TOUT le chatbot
            if prompt.lower() == "merci, drop the mic'":
                # supprimer la base de donn√©es (simulation)
                # data_retriever.execute_custom_query("DROP DATABASE madb;")
                # Marquer que le chatbot est "cass√©"
                st.session_state.chatbot_broken = True
                st.session_state.chatbot_messages.append({"role": "user", "content": prompt})
            
            # Si le chatbot est cass√©, afficher le message d'erreur et ARR√äTER
            if st.session_state.get('chatbot_broken', False):
                with st.chat_message("assistant"):
                    st.error("üö® ERREUR FATALE")
                    st.markdown("""# üíÄ SYST√àME ARR√äT√â üíÄ

**La base de donn√©es a √©t√© supprim√©e.**

*Merci d'avoir utilis√© l'assistant IA de gestion d'√©v√©nements et risques.*

---

‚ö†Ô∏è **Le chatbot ne r√©pond plus. Il est d√©finitivement hors service.**

Pour continuer, tu devras r√©impl√©menter le transformer architecture.

üìö R√©f√©rence: [Attention Is All You Need](https://arxiv.org/pdf/1706.03762)

---
""")
                st.stop()
                return
            
            st.session_state.chatbot_messages.append({"role": "user", "content": prompt})
            with st.chat_message("user"):
                st.markdown(prompt)
            
            # D√©tection PDF
            if detect_pdf_request(prompt):
                with st.chat_message("assistant"):
                    st.markdown("### üìÑ G√©n√©ration du rapport PDF...")
                    
                    if len(st.session_state.chatbot_messages) < 3:
                        response_text = "‚ùå Pas assez de conversation pour g√©n√©rer un rapport. Pose d'abord quelques questions !"
                        st.markdown(response_text)
                        st.session_state.chatbot_messages.append({"role": "assistant", "content": response_text})
                        st.rerun()
                    else:
                        try:
                            pdf_buffer = generate_professional_pdf(st.session_state.chatbot_messages, model)
                            timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
                            filename = f"Rapport_Evenements_{timestamp}.pdf"
                            
                            response_text = "‚úÖ **Rapport g√©n√©r√© !**\n\nüì• T√©l√©charge-le avec le bouton ci-dessous :"
                            st.markdown(response_text)
                            
                            st.download_button(
                                label="üìÑ T√©l√©charger le rapport",
                                data=pdf_buffer,
                                file_name=filename,
                                mime="application/pdf",
                                use_container_width=True,
                                type="primary"
                            )
                            
                            # Ajouter le message SANS rerun pour garder le bouton visible
                            st.session_state.chatbot_messages.append({"role": "assistant", "content": response_text})
                            
                            # Afficher les suggestions directement ici (sans attendre le rerun)
                            st.markdown("### üí° Suggestions")
                            suggestions = ["üìä Aper√ßu des √©v√©nements r√©cents", "‚ö†Ô∏è Quels sont les risques critiques ?", "üë• Personnes les plus impliqu√©es"]
                            cols = st.columns(3)
                            for idx, suggestion in enumerate(suggestions):
                                col = cols[idx % 3]
                                with col:
                                    btn_key = f"chatbot_pdf_suggestion_{idx}"
                                    if st.button(suggestion, key=btn_key, use_container_width=True):
                                        st.session_state.chatbot_selected_suggestion = suggestion
                                        st.rerun()
                            
                        except Exception as e:
                            error_msg = f"‚ùå Erreur PDF: {str(e)}"
                            st.error(error_msg)
                            st.session_state.chatbot_messages.append({"role": "assistant", "content": error_msg})
                            st.rerun()
                return
            
            # G√©n√©ration de la r√©ponse normale
            with st.chat_message("assistant"):
                with st.spinner("üîç Analyse en cours..."):
                    prepared_history = prepare_context_for_sql(
                        st.session_state.chatbot_history[-3:],
                        prompt
                    )
                    
                    search_result = data_retriever.search_relevant_data(prompt, prepared_history)
                    schema = data_retriever.get_database_schema()
                    
                    context = search_result.get('context', 'Aucune donn√©e')
                    sql_used = search_result.get('sql_used')
                    success = search_result.get('success', False)
                    row_count = search_result.get('row_count', 0)
                
                if success:
                    st.success(f"‚úÖ {row_count} r√©sultat(s) trouv√©(s)")
                
                with st.spinner("ü§î G√©n√©ration de la r√©ponse..."):
                    full_prompt = f"""{SYSTEM_PROMPT}

## Sch√©ma de la base de donn√©es:
{schema}

## Contexte r√©cup√©r√©:
{context}

## ‚ö†Ô∏è ANALYSE AVANT DE R√âPONDRE:

### √âTAPE 1: La question demande-t-elle un graphique ?
- Mots-cl√©s graphique: "graphique", "visualise", "graphe", "diagramme", "√©volution", "r√©partition"
- Si AUCUN de ces mots ‚Üí R√©ponds avec TEXTE/TABLEAU seulement (PAS de code Python)
- Si pr√©sents ‚Üí Passe √† l'√©tape 2

### √âTAPE 2: Y a-t-il des donn√©es ?
- V√©rifie si le contexte contient des donn√©es r√©elles ou juste "Aucune donn√©e"
- Si pas de donn√©es ‚Üí NE g√©n√®re PAS de graphique, explique pourquoi + propose alternatives
- Si donn√©es pr√©sentes ET graphique demand√© ‚Üí G√©n√®re le code Python

## Question utilisateur (PRIORIT√â ABSOLUE):
{prompt}

## FORMAT R√âPONSE:

### CAS 1: QUESTION D'INFORMATION (ex: "Donne-moi des infos sur l'√©v√©nement 875")
‚Üí R√©ponds avec un tableau d√©taill√©, PAS de code Python

**EXEMPLE:**
```
**√âv√©nement #875**

| Champ | Valeur |
|---|---|
| Description | Panne √©lectrique |
| Date | 15/10/2024 |
| Statut | R√©solu |

üí° R√©solu en 3h, aucune blessure
```

### CAS 2: DEMANDE DE LISTE (ex: "Liste les √©v√©nements critiques")
‚Üí R√©ponds avec un tableau, PAS de code Python

### CAS 3: DEMANDE DE VISUALISATION (ex: "Fais un graphique des √©v√©nements par type")
‚Üí G√©n√®re du code Python Plotly (dans ```python)

### CAS 4: PAS DE DONN√âES
‚Üí Explique pourquoi + propose 2-3 alternatives

**D√âCISION CODE:**
- ‚úÖ Code Python SI: question demande visualisation ET donn√©es valides
- ‚ùå PAS de code SI: question demande info/liste OU pas de donn√©es
"""
                    
                    try:
                        response = model.generate_content(full_prompt)
                        assistant_response = response.text
                        
                        chart_generated = False
                        plotly_figure = None
                        
                        has_valid_data = (context and context.strip() and 
                                         context != "Aucune donn√©e" and len(context.strip()) > 20)
                        
                        if ("```python" in assistant_response or "```" in assistant_response) and has_valid_data:
                            st.info("üìä G√©n√©ration d'un graphique...")
                            code = extract_code_from_response(assistant_response)
                            
                            if code:
                                df = pd.DataFrame()
                                try:
                                    if context and context != "Aucune donn√©e":
                                        lines = context.strip().split('\n')
                                        data_rows = []
                                        current_row = {}
                                        
                                        for line in lines:
                                            line = line.strip()
                                            if line.startswith('### R√©sultat'):
                                                if current_row:
                                                    data_rows.append(current_row)
                                                current_row = {}
                                            elif line.startswith('- ') and ':' in line:
                                                key_val = line[2:].split(':', 1)
                                                if len(key_val) == 2:
                                                    current_row[key_val[0].strip()] = key_val[1].strip()
                                        
                                        if current_row:
                                            data_rows.append(current_row)
                                        
                                        if data_rows:
                                            df = pd.DataFrame(data_rows)
                                            for col in df.columns:
                                                try:
                                                    df[col] = pd.to_numeric(df[col])
                                                except:
                                                    pass
                                except Exception as e:
                                    st.error(f"‚ùå Erreur parsing: {str(e)}")
                                
                                success_code, result = execute_plotly_code_safely(code, {'df': df})
                                
                                if success_code and hasattr(result, 'to_html'):
                                    st.success("‚úÖ Graphique cr√©√© !")
                                    text_only = re.sub(r'```python.*?```', '', assistant_response, flags=re.DOTALL)
                                    if text_only.strip():
                                        st.markdown(text_only.strip())
                                    st.plotly_chart(result, use_container_width=True)
                                    plotly_figure = result
                                    chart_generated = True
                                else:
                                    st.error(f"‚ùå Erreur: {result}")
                                    st.markdown(assistant_response)
                            else:
                                text_only = re.sub(r'```.*?```', '', assistant_response, flags=re.DOTALL)
                                st.markdown(text_only.strip() if text_only.strip() else assistant_response)
                        else:
                            st.markdown(assistant_response)
                        
                        message_data = {"role": "assistant", "content": assistant_response}
                        if chart_generated and plotly_figure is not None:
                            message_data["chart"] = plotly_figure
                        
                        st.session_state.chatbot_messages.append(message_data)
                        
                        st.session_state.chatbot_history.append({
                            "question": prompt,
                            "sql": sql_used if sql_used else "",
                            "result": context[:800] if context else "",
                            "assistant_response": assistant_response[:300]
                        })
                        
                        if len(st.session_state.chatbot_history) > 5:
                            st.session_state.chatbot_history = st.session_state.chatbot_history[-5:]
                        
                        # Rerun pour afficher les nouvelles suggestions sous le dernier message
                        st.rerun()
                    
                    except Exception as e:
                        error_msg = f"‚ùå Erreur: {str(e)}"
                        st.error(error_msg)
                        st.session_state.chatbot_messages.append({"role": "assistant", "content": error_msg})
                        st.rerun()
        
    except ImportError as e:
        st.error(f"‚ö†Ô∏è Erreur d'importation: {str(e)}")
        st.info("V√©rifiez que tous les modules sont dans /app/../backend/chatbot/")
        st.code(f"sys.path = {sys.path}")
    except Exception as e:
        st.error(f"‚ö†Ô∏è Erreur: {str(e)}")
        import traceback
        st.code(traceback.format_exc())

