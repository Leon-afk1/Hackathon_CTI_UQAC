"""
Application Streamlit pour un chatbot RAG utilisant Gemini
avec acc√®s √† la base de donn√©es PostgreSQL d'√©v√©nements.
"""

import streamlit as st
import os
from dotenv import load_dotenv
import google.generativeai as genai
from data_retriever import data_retriever

# Configuration de la page Streamlit
st.set_page_config(
    page_title="Assistant Gestion d'√âv√©nements",
    page_icon="üõ°Ô∏è",
    layout="wide"
)

# --- Configuration de l'API Gemini ---
load_dotenv()
API_KEY = os.getenv("GEMINI_API_KEY")

if not API_KEY:
    st.error("‚ö†Ô∏è Cl√© API Gemini non trouv√©e. D√©finis GEMINI_API_KEY dans ton fichier .env")
    st.stop()

genai.configure(api_key=API_KEY)

# Initialisation du mod√®le
@st.cache_resource
def init_gemini_model():
    """Initialize le mod√®le Gemini avec fallback."""
    try:
        model = genai.GenerativeModel('gemini-2.5-flash')
        return model, "gemini-2.5-flash"
    except Exception as e:
        st.warning(f"Erreur avec gemini-2.5-flash: {e}. Fallback vers gemini-pro.")
        try:
            model = genai.GenerativeModel('gemini-pro')
            return model, "gemini-pro"
        except Exception as e:
            st.error(f"Impossible d'initialiser un mod√®le Gemini: {e}")
            return None, None

model, model_name = init_gemini_model()

if model is None:
    st.stop()

# Prompt syst√®me pour le chatbot
SYSTEM_PROMPT = """Tu es un expert en analyse d'√©v√©nements. R√©ponds de mani√®re SYNTH√âTIQUE et RAPIDE.

## BASE DE DONN√âES
- event (√©v√©nements centraux)
- person (employ√©s)
- risk (risques)  
- corrective_measure (actions)
- organizational_unit (services)
- Tables liaison: event_employee, event_risk, event_corrective_measure

## STYLE DE R√âPONSE
1. **VA DROIT AU BUT** - L'utilisateur veut une info rapide
2. **SYNTH√âTISE** - R√©sume, n'√©tale pas
3. **STRUCTURE** - Tableaux courts, puces, chiffres cl√©s
4. **EXPLIQUE** - Dis ce que tu as trouv√© et pourquoi c'est important
5. **SOIS PR√âCIS** - Cite les IDs, noms, chiffres exacts

## EXEMPLES

‚ùå MAL: "Bien s√ªr ! Je suis ravi de vous aider. Voici une liste exhaustive de tous les √©v√©nements..."

‚úÖ BIEN: "**5 √©v√©nements r√©cents:**
| ID | Description | Date | Type |
|---|---|---|---|
| 125 | Panne ligne A | 28/10 | Incident |

üí° 3 sont critiques, 2 r√©solus"

## TON APPROCHE
- Commence direct (pas de "bien s√ªr, je serais ravi...")
- Mets les chiffres importants en avant
- Propose une action si pertinent
- Si pas de donn√©es: dis-le et propose alternative
"""

# --- Interface Streamlit ---

# En-t√™te
st.title("üõ°Ô∏è Assistant Gestion d'√âv√©nements & Risques")
st.markdown(f"*Propuls√© par {model_name}*")

# Barre lat√©rale avec informations
with st.sidebar:
    st.header("ÔøΩ Bienvenue !")
    st.markdown("""
    Pose tes questions sur les √©v√©nements, risques et mesures correctives.
    
    **Exemples:**
    - "√âv√©nements r√©cents ?"
    - "Risques critiques ?"
    - "Mesures en cours ?"
    - "Qui a d√©clar√© le plus d'√©v√©nements ?"
    """)
    
    st.divider()
    

    
    if st.button("üîÑ R√©initialiser"):
        st.session_state.messages = []
        st.rerun()

# Initialisation de l'historique des messages et de la conversation
if "messages" not in st.session_state:
    st.session_state.messages = []
    welcome_message = """### üëã Assistant √âv√©nements

Je r√©ponds rapidement √† vos questions sur:
- üìã √âv√©nements & incidents
- ‚ö†Ô∏è Risques  
- ‚úÖ Mesures correctives
- üë• Personnes impliqu√©es

**Exemples:**
- "√âv√©nements r√©cents"
- "Risques critiques"
- "Qui dans √©v√©nement 5?"
- "Co√ªt total mesures"

**Pose ta question !** üöÄ
"""
    st.session_state.messages.append({
        "role": "assistant",
        "content": welcome_message
    })

# Initialisation de l'historique de conversation (pour m√©moire SQL)
if "conversation_history" not in st.session_state:
    st.session_state.conversation_history = []

# Affichage de l'historique des messages
for message in st.session_state.messages:
    with st.chat_message(message["role"]):
        st.markdown(message["content"])

# Zone de saisie utilisateur
if prompt := st.chat_input("Posez votre question sur les √©v√©nements, risques ou mesures..."):
    # Ajout du message utilisateur
    st.session_state.messages.append({"role": "user", "content": prompt})
    with st.chat_message("user"):
        st.markdown(prompt)
    
    # G√©n√©ration de la r√©ponse
    with st.chat_message("assistant"):
        # Afficher un indicateur si on utilise l'historique
        history_size = len(st.session_state.conversation_history)
        if history_size > 0:
            with st.expander(f"üß† M√©moire active: {history_size} √©change(s) pr√©c√©dent(s)", expanded=False):
                for i, ex in enumerate(st.session_state.conversation_history[-3:], 1):
                    st.caption(f"{i}. Q: {ex.get('question', 'N/A')[:60]}...")
        
        with st.spinner("üîç Analyse de la question et g√©n√©ration de la requ√™te SQL..."):
            # R√©cup√©ration du contexte depuis la base de donn√©es avec SQL intelligent
            # On passe les 5 derniers √©changes comme historique
            search_result = data_retriever.search_relevant_data(
                prompt, 
                st.session_state.conversation_history[-5:]  # Garde seulement les 5 derniers
            )
            schema = data_retriever.get_database_schema()
            
            # Extraction des informations du r√©sultat
            context = search_result.get('context', 'Aucune donn√©e')
            sql_used = search_result.get('sql_used')
            explanation = search_result.get('explanation', '')
            success = search_result.get('success', False)
            row_count = search_result.get('row_count', 0)
        
        # Affichage d'informations sur la requ√™te
        attempts = search_result.get('attempts', 1)
        if success and sql_used:
            attempt_msg = f" (1√®re tentative)" if attempts == 1 else f" (tentative {attempts}/5)"
            st.success(f"‚úÖ Requ√™te ex√©cut√©e avec succ√®s{attempt_msg} - {row_count} r√©sultat(s) trouv√©(s)")
        elif not success:
            if attempts >= 5:
                st.error(f"‚ùå √âchec apr√®s {attempts} tentatives - Abandon de la g√©n√©ration SQL")
                st.info("üí° Conseil: Reformule ta question de mani√®re plus pr√©cise ou utilise des IDs exacts")
            else:
                attempt_msg = f" apr√®s {attempts} tentative(s)" if attempts > 1 else ""
                st.warning(f"‚ö†Ô∏è √âchec{attempt_msg} - {search_result.get('error', 'Erreur inconnue')}")
        
        with st.spinner("ü§î G√©n√©ration de la r√©ponse intelligente..."):
            # Construction du prompt complet
            full_prompt = f"""{SYSTEM_PROMPT}

## Sch√©ma de la base de donn√©es:
{schema}

## Contexte r√©cup√©r√© depuis la base de donn√©es:
{context}

## Question utilisateur:
{prompt}

## FORMAT R√âPONSE:

**STRUCTURE OBLIGATOIRE:**
1. R√©sum√© en 1 ligne (chiffre cl√©)
2. Tableau compact (max 5 colonnes essentielles)
3. Insight/observation importante (1 phrase avec üí°)

**EXEMPLE:**
```
**15 √©v√©nements trouv√©s** (10 derniers affich√©s)

| ID | Description | Date | Type |
|---|---|---|---|
| 125 | Panne ligne A | 28/10 | Incident |
| 124 | Chute escalier | 27/10 | Accident |

üí° 40% sont de type "Incident", majoritairement r√©solus
```

**R√àGLES:**
- Max 10 lignes de tableau
- Dates format court: JJ/MM
- Pas de phrases longues
- Mets en gras les chiffres importants
- Si >10 r√©sultats: indique le total mais affiche que 10
"""
            
            try:
                # G√©n√©ration de la r√©ponse avec Gemini
                response = model.generate_content(full_prompt)
                assistant_response = response.text
                
                # Affichage de la r√©ponse
                st.markdown(assistant_response)
                
                # Ajout √† l'historique des messages
                st.session_state.messages.append({
                    "role": "assistant",
                    "content": assistant_response
                })
                
                # Ajout √† l'historique de conversation (pour la m√©moire SQL)
                # Extraire les informations cl√©s de la r√©ponse pour le contexte
                result_summary = context[:800] if context else ""  # Garde plus de contexte
                
                st.session_state.conversation_history.append({
                    "question": prompt,
                    "sql": sql_used if sql_used else "",
                    "result": result_summary,
                    "assistant_response": assistant_response[:300]  # D√©but de la r√©ponse du chatbot
                })
                
                # Garde seulement les 5 derniers √©changes (m√©moire courte terme)
                if len(st.session_state.conversation_history) > 5:
                    st.session_state.conversation_history = st.session_state.conversation_history[-5:]
                
                # Affichage optionnel des d√©tails techniques (dans un expander)
                with st.expander("üîç Voir les d√©tails techniques (SQL & donn√©es)"):
                    if sql_used:
                        st.markdown("### üìù Requ√™te SQL g√©n√©r√©e (format√©e pour debug):")
                        st.code(sql_used, language="sql")
                        
                        # Afficher aussi la version raw si disponible
                        if 'sql_raw' in search_result and search_result['sql_raw'] != sql_used:
                            st.markdown("**Version compacte (ex√©cut√©e):**")
                            st.code(search_result['sql_raw'], language="sql")
                        
                        if explanation:
                            st.markdown(f"**Explication:** {explanation}")
                        
                        if 'attempts' in search_result:
                            st.info(f"üîÑ Nombre de tentatives: {search_result['attempts']}")
                    
                    st.markdown("### üìä Donn√©es r√©cup√©r√©es:")
                    st.text(context[:2000] + ("..." if len(context) > 2000 else ""))
                    
                    if not success:
                        if 'error' in search_result:
                            st.markdown("### ‚ö†Ô∏è Erreur:")
                            st.error(search_result['error'])
                        if 'traceback' in search_result:
                            st.markdown("**Trace compl√®te:**")
                            st.code(search_result['traceback'], language="python")
                
            except Exception as e:
                error_msg = f"‚ùå Erreur lors de la g√©n√©ration de la r√©ponse: {str(e)}"
                st.error(error_msg)
                st.session_state.messages.append({
                    "role": "assistant",
                    "content": error_msg
                })

# Footer
st.markdown("---")
st.markdown("*üí° Conseil: Posez des questions pr√©cises pour obtenir les meilleures r√©ponses.*")
